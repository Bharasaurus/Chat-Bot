{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ILiNay8jDMKyXIy1R2N6YSPGV9A8GjgA",
      "authorship_tag": "ABX9TyN0IovMmQyTS5Z0g9BtM4b4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharasaurus/Chat-Bot/blob/main/Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1ZQxu2uXlMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895390b4-dd34-4995-d5d6-4c60a06e8975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import string\n",
        "import torch\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "def Bag_of_Words(tokenized_sentence, all_words):\n",
        "  sentence=[stem(word) for word in tokenized_sentence]\n",
        "  bag=np.zeros(len(all_words),dtype=np.float32)\n",
        "  for i,word in enumerate(all_words):\n",
        "    if(word in sentence):\n",
        "      bag[i]=1.0\n",
        "  return bag"
      ],
      "metadata": {
        "id": "DwMlmYvfX7_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Deep Learning/Colab Notebooks/Chat Bot/Intents.json\",'r') as obj:\n",
        "  intents=json.load(obj)\n",
        "print(intents)\n",
        "all_words=[]\n",
        "tags=[]\n",
        "xy=[]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akyqMKdGYBJK",
        "outputId": "0c54ee5d-8dd3-41f5-d842-9e6796decbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}, {'tag': 'help', 'patterns': ['Can you help me?', 'I need assistance', 'Help me, please'], 'responses': ['Of course! What do you need help with?', \"I'm here to assist you. What can I do for you?\", \"Sure, I'll do my best to help. What's the issue?\"]}, {'tag': 'location', 'patterns': ['Where are you located?', \"What's your address?\", 'Tell me your location'], 'responses': ['We are located at 123 Main Street, Cityville', 'Our address is 456 Park Avenue, Townsville']}, {'tag': 'menu', 'patterns': [\"What's on the menu?\", 'Tell me about your menu', 'What can I order?'], 'responses': ['Our menu includes a variety of delicious dishes, from burgers to salads.', 'You can find a diverse menu featuring pizzas, pastas, and more.']}, {'tag': 'business_hours', 'patterns': ['What are your business hours?', 'When are you open?', 'Tell me your opening hours'], 'responses': ['We are open from 9 AM to 6 PM, Monday to Friday.', 'Our business hours are 8:30 AM to 7 PM on weekdays and 10 AM to 4 PM on weekends.']}, {'tag': 'feedback', 'patterns': ['How can I provide feedback?', 'I have a suggestion', 'Give feedback'], 'responses': ['We appreciate your feedback! You can share your thoughts through our website or contact us directly.', 'Your feedback is valuable to us. Feel free to share your suggestions on our feedback platform.']}, {'tag': 'weather', 'patterns': [\"What's the weather like today?\", 'Tell me the weather forecast', 'Is it going to rain?'], 'responses': [\"I'm sorry, but I don't have real-time weather information. You can check a reliable weather website or app for the current forecast.\", \"Unfortunately, I can't provide live weather updates. Please check a weather service for the latest information.\"]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents[\"intents\"]:\n",
        "  tag=intent[\"tag\"]\n",
        "  tags.append(tag)\n",
        "  for pattern in intent[\"patterns\"]:\n",
        "    all_words.extend(tokenize(pattern))\n",
        "    xy.append((tokenize(pattern),tag))\n",
        "all_words=[stem(word) for word in all_words if word not in string.punctuation]\n",
        "all_words=sorted(set(all_words))\n",
        "tags=sorted(set(tags))\n",
        "print(xy)"
      ],
      "metadata": {
        "id": "K-kjXDOHYCtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c611cebe-76b3-4699-a91a-f8a596f1bac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['Hi'], 'greeting'), (['Hey'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Thank', \"'s\", 'a', 'lot', '!'], 'thanks'), (['Which', 'items', 'do', 'you', 'have', '?'], 'items'), (['What', 'kinds', 'of', 'items', 'are', 'there', '?'], 'items'), (['What', 'do', 'you', 'sell', '?'], 'items'), (['Do', 'you', 'take', 'credit', 'cards', '?'], 'payments'), (['Do', 'you', 'accept', 'Mastercard', '?'], 'payments'), (['Can', 'I', 'pay', 'with', 'Paypal', '?'], 'payments'), (['Are', 'you', 'cash', 'only', '?'], 'payments'), (['How', 'long', 'does', 'delivery', 'take', '?'], 'delivery'), (['How', 'long', 'does', 'shipping', 'take', '?'], 'delivery'), (['When', 'do', 'I', 'get', 'my', 'delivery', '?'], 'delivery'), (['Tell', 'me', 'a', 'joke', '!'], 'funny'), (['Tell', 'me', 'something', 'funny', '!'], 'funny'), (['Do', 'you', 'know', 'a', 'joke', '?'], 'funny'), (['Can', 'you', 'help', 'me', '?'], 'help'), (['I', 'need', 'assistance'], 'help'), (['Help', 'me', ',', 'please'], 'help'), (['Where', 'are', 'you', 'located', '?'], 'location'), (['What', \"'s\", 'your', 'address', '?'], 'location'), (['Tell', 'me', 'your', 'location'], 'location'), (['What', \"'s\", 'on', 'the', 'menu', '?'], 'menu'), (['Tell', 'me', 'about', 'your', 'menu'], 'menu'), (['What', 'can', 'I', 'order', '?'], 'menu'), (['What', 'are', 'your', 'business', 'hours', '?'], 'business_hours'), (['When', 'are', 'you', 'open', '?'], 'business_hours'), (['Tell', 'me', 'your', 'opening', 'hours'], 'business_hours'), (['How', 'can', 'I', 'provide', 'feedback', '?'], 'feedback'), (['I', 'have', 'a', 'suggestion'], 'feedback'), (['Give', 'feedback'], 'feedback'), (['What', \"'s\", 'the', 'weather', 'like', 'today', '?'], 'weather'), (['Tell', 'me', 'the', 'weather', 'forecast'], 'weather'), (['Is', 'it', 'going', 'to', 'rain', '?'], 'weather'), (['Hi'], 'greeting'), (['Hey'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Thank', \"'s\", 'a', 'lot', '!'], 'thanks'), (['Which', 'items', 'do', 'you', 'have', '?'], 'items'), (['What', 'kinds', 'of', 'items', 'are', 'there', '?'], 'items'), (['What', 'do', 'you', 'sell', '?'], 'items'), (['Do', 'you', 'take', 'credit', 'cards', '?'], 'payments'), (['Do', 'you', 'accept', 'Mastercard', '?'], 'payments'), (['Can', 'I', 'pay', 'with', 'Paypal', '?'], 'payments'), (['Are', 'you', 'cash', 'only', '?'], 'payments'), (['How', 'long', 'does', 'delivery', 'take', '?'], 'delivery'), (['How', 'long', 'does', 'shipping', 'take', '?'], 'delivery'), (['When', 'do', 'I', 'get', 'my', 'delivery', '?'], 'delivery'), (['Tell', 'me', 'a', 'joke', '!'], 'funny'), (['Tell', 'me', 'something', 'funny', '!'], 'funny'), (['Do', 'you', 'know', 'a', 'joke', '?'], 'funny'), (['Can', 'you', 'help', 'me', '?'], 'help'), (['I', 'need', 'assistance'], 'help'), (['Help', 'me', ',', 'please'], 'help'), (['Where', 'are', 'you', 'located', '?'], 'location'), (['What', \"'s\", 'your', 'address', '?'], 'location'), (['Tell', 'me', 'your', 'location'], 'location'), (['What', \"'s\", 'on', 'the', 'menu', '?'], 'menu'), (['Tell', 'me', 'about', 'your', 'menu'], 'menu'), (['What', 'can', 'I', 'order', '?'], 'menu'), (['What', 'are', 'your', 'business', 'hours', '?'], 'business_hours'), (['When', 'are', 'you', 'open', '?'], 'business_hours'), (['Tell', 'me', 'your', 'opening', 'hours'], 'business_hours'), (['How', 'can', 'I', 'provide', 'feedback', '?'], 'feedback'), (['I', 'have', 'a', 'suggestion'], 'feedback'), (['Give', 'feedback'], 'feedback'), (['What', \"'s\", 'the', 'weather', 'like', 'today', '?'], 'weather'), (['Tell', 'me', 'the', 'weather', 'forecast'], 'weather'), (['Is', 'it', 'going', 'to', 'rain', '?'], 'weather')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=[]\n",
        "Y_train=[]\n",
        "for (pattern_sentence, tag) in xy:\n",
        "  bag=Bag_of_Words(pattern_sentence,all_words)\n",
        "  X_train.append(bag)\n",
        "  label=tags.index(tag)\n",
        "  Y_train.append(label)\n",
        "X_train=np.array(X_train)\n",
        "X_train = X_train / np.max(X_train, axis=1, keepdims=True)\n",
        "print(len(X_train))\n",
        "Y_train=np.array(Y_train)\n",
        "class ChatDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.n_samples=len(X_train)\n",
        "    self.x_data=X_train\n",
        "    self.y_data=Y_train\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x_data[index],self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "#Hyperparameter\n",
        "\n",
        "batch_size=8\n",
        "hidden_size=8\n",
        "output_size=len(tags)\n",
        "input_size=len(X_train[0])\n",
        "learning_rate=0.001\n",
        "num_epochs=1000\n",
        "\n",
        "dataset=ChatDataset()\n",
        "train_loader=DataLoader(dataset=dataset, batch_size=batch_size,shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "W5e6IZp3ahYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1065429d-8a75-4dff-fdbf-3b1b934054f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Learning Model\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.l1=nn.Linear(input_size,hidden_size)\n",
        "    self.l2=nn.Linear(hidden_size,hidden_size)\n",
        "    self.l3=nn.Linear(hidden_size,hidden_size)\n",
        "    self.l4=nn.Linear(hidden_size, num_classes)\n",
        "    self.relu=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.l2(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.l3(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.l4(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "E2Nl34QBBBSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=NeuralNet(input_size,hidden_size,output_size).to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "  for (words,labels) in train_loader:\n",
        "    words=words.to(device)\n",
        "    labels=labels.to(device)\n",
        "    #Forward\n",
        "    outputs=model(words)\n",
        "    loss=criterion(outputs,labels)\n",
        "    #Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if(epoch+1)%100==0:\n",
        "    print(f\"epoch {epoch+1}/{num_epochs}, loss={loss.item():.4f}\")\n",
        "\n",
        "print(f\"Final Loss - {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "pM1sSjO7CScI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08219785-d62a-4163-97f2-6e07960a2c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100/1000, loss=2.4564\n",
            "epoch 200/1000, loss=1.6840\n",
            "epoch 300/1000, loss=1.1307\n",
            "epoch 400/1000, loss=0.8747\n",
            "epoch 500/1000, loss=0.6221\n",
            "epoch 600/1000, loss=0.3470\n",
            "epoch 700/1000, loss=0.2782\n",
            "epoch 800/1000, loss=0.1122\n",
            "epoch 900/1000, loss=0.1424\n",
            "epoch 1000/1000, loss=0.0695\n",
            "Final Loss - 0.0695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.Sequential([\n",
        "#     keras.layers.Dense(128, input_shape=(len(X_train[0]),), activation='relu'),\n",
        "#     keras.layers.Dropout(0.5),\n",
        "#     keras.layers.Dense(64, activation='relu'),\n",
        "#     keras.layers.Dropout(0.5),\n",
        "#     keras.layers.Dense(32, activation='relu'),\n",
        "#     keras.layers.Dropout(0.5),\n",
        "#     keras.layers.Dense(len(tags), activation='softmax')\n",
        "# ])\n",
        "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
        "# optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "# model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train, Y_train, epochs=1000)"
      ],
      "metadata": {
        "id": "DruqbICJIDlf"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feed-Back Loop\n",
        "\n",
        "def incremental_train(model, optimizer, criterion, new_patterns, new_labels, num_epochs=100):\n",
        "    new_patterns = [Bag_of_Words(pattern, all_words) for pattern in new_patterns]\n",
        "    new_labels = [tags.index(label) for label in new_labels]\n",
        "\n",
        "    new_patterns = np.array(new_patterns)\n",
        "    new_patterns = new_patterns / np.max(new_patterns, axis=1, keepdims=True)\n",
        "    new_labels = np.array(new_labels)\n",
        "\n",
        "    new_dataset = ChatDataset()\n",
        "    new_dataset.x_data = new_patterns\n",
        "    new_dataset.y_data = new_labels\n",
        "    new_loader = DataLoader(dataset=new_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for (words, labels) in new_loader:\n",
        "            words = words.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward\n",
        "            outputs = model(words)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Incremental Training - epoch {epoch + 1}/{num_epochs}, loss={loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "C3lhPttnnF1R"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name=\"Sam\"\n",
        "print(\"Let's Chat! Type 'quit' to exit\")\n",
        "while True:\n",
        "  sentence=input(\"You - \")\n",
        "  if(sentence.lower()==\"quit\"):\n",
        "    break\n",
        "  sentence=tokenize(sentence)\n",
        "  X=Bag_of_Words(sentence, all_words)\n",
        "  X=X.reshape(1,X.shape[0])\n",
        "  X=torch.from_numpy(X)\n",
        "  X=X.to(device)\n",
        "  output=model(X)\n",
        "  _, predicted=torch.max(output,dim=1)\n",
        "  tag=tags[predicted.item()]\n",
        "  probs=torch.softmax(output, dim=1)\n",
        "  prob=probs[0][predicted.item()]\n",
        "  if prob.item() > 0.75:\n",
        "    for intent in intents[\"intents\"]:\n",
        "      if tag == intent[\"tag\"]:\n",
        "        response = random.choice(intent['responses'])\n",
        "        print(f\"{bot_name} - {response}\")\n",
        "\n",
        "        # Ask for user feedback\n",
        "        user_feedback = input(\"Did this answer your question? (yes/no): \")\n",
        "        if user_feedback.lower() == \"no\":\n",
        "          comment = input(\"Please provide additional comments: \")\n",
        "          # Update intents with new patterns\n",
        "          new_patterns = tokenize(comment)\n",
        "          intents[\"intents\"].append({\n",
        "                        \"tag\": \"custom\",\n",
        "                        \"patterns\": new_patterns,\n",
        "                        \"responses\": [\"Thank you for your input. We'll improve our responses.\"]})\n",
        "          incremental_train(model, optimizer, criterion, new_patterns, [\"custom\"], num_epochs=50)\n",
        "\n",
        "  else:\n",
        "        print(f\"{bot_name}: Sorry, please repeat your prompt\")\n"
      ],
      "metadata": {
        "id": "RKYzZYBo_eKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65c705d-5339-457f-c956-ae4be1040ed9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's Chat! Type 'quit' to exit\n",
            "You - hello\n",
            "Sam - Hi there, how can I help?\n",
            "Did this answer your question? (yes/no): yes\n",
            "You - jokes pls\n",
            "Sam - What did the buffalo say when his son left for college? Bison.\n",
            "Did this answer your question? (yes/no): yes\n",
            "You - loll\n",
            "Sam: Sorry, please repeat your prompt\n",
            "You - bye\n",
            "Sam - Bye! Come back again soon.\n",
            "Did this answer your question? (yes/no): yes\n",
            "You - quit\n"
          ]
        }
      ]
    }
  ]
}